# ğŸ  PrÃ©diction du Prix des Maisons - Ames Housing Dataset


Projet complet de Machine Learning pour prÃ©dire le prix des maisons en utilisant le cÃ©lÃ¨bre dataset Ames Housing. Ce projet dÃ©montre un pipeline complet de Data Science, de l'exploration des donnÃ©es Ã  la modÃ©lisation prÃ©dictive.

## ğŸ“Š AperÃ§u du Projet

Ce projet a Ã©tÃ© rÃ©alisÃ© dans le cadre du Master 2 Data Science et Machine Learning Ã  l'INPHB. Il met en Å“uvre un processus complet d'analyse de donnÃ©es et de modÃ©lisation prÃ©dictive sur le dataset Ames Housing, contenant des informations sur ~2930 ventes de propriÃ©tÃ©s rÃ©sidentielles.

### ğŸ¯ Objectifs

- Analyser en profondeur les facteurs qui influencent le prix des propriÃ©tÃ©s
- Nettoyer et prÃ©parer les donnÃ©es pour la modÃ©lisation
- Construire un modÃ¨le prÃ©dictif robuste et interprÃ©table
- Ã‰valuer les performances et identifier les variables clÃ©s
- Fournir des recommandations actionnables

## ğŸ“ˆ RÃ©sultats ClÃ©s

| MÃ©trique | Valeur | InterprÃ©tation |
|----------|--------|----------------|
| **RÂ² Score** | 82.60% | Excellent niveau de prÃ©diction |
| **RMSE** | $37,349 | Erreur quadratique moyenne |
| **MAE** | $17,501 | Erreur typique (~10% du prix moyen) |
| **Erreur moyenne** | -0.71% | Pas de biais systÃ©matique |

âœ… **Le modÃ¨le explique 82.60% de la variance des prix !**

## ğŸ—‚ï¸ Structure du Projet

```
ames-housing-prediction/
â”‚
â”œâ”€â”€ notebook_final_enrichi.ipynb    # Notebook principal avec analyses complÃ¨tes
â”œâ”€â”€ AmesHousing.csv                 # Dataset (Ã  tÃ©lÃ©charger)
â”œâ”€â”€ README.md                       # Ce fichier
â”œâ”€â”€ requirements.txt                # DÃ©pendances Python                       # Licence MIT
â””â”€â”€ .gitignore                      # Fichiers Ã  ignorer
```

## ğŸ› ï¸ Technologies UtilisÃ©es

- **Python 3.8+**
- **pandas** - Manipulation de donnÃ©es
- **numpy** - Calculs numÃ©riques
- **scikit-learn** - Machine Learning
- **matplotlib** - Visualisations
- **seaborn** - Visualisations statistiques
- **scipy** - Analyses statistiques

## ğŸ“‹ Table des MatiÃ¨res du Notebook

### Partie I : PrÃ©paration et Exploration
1. **Importations et Configuration**
2. **Chargement et Exploration Initiale**
3. **Nettoyage et Traitement des Valeurs Manquantes**

### Partie II : Analyses Statistiques
4. **Analyse UnivariÃ©e**
5. **Analyse BivariÃ©e** (Variables numÃ©riques et catÃ©gorielles)
6. **Analyse MultivariÃ©e** (CorrÃ©lations et multicolinÃ©aritÃ©)

### Partie III : ModÃ©lisation
7. **Feature Engineering et PrÃ©paration**
   - Transformation logarithmique
   - Encodage des variables catÃ©gorielles
   - Division Train/Test
   - Standardisation
8. **ModÃ©lisation et Ã‰valuation** (RÃ©gression LinÃ©aire)
9. **InterprÃ©tation Approfondie des RÃ©sultats**

## ğŸš€ Installation et Utilisation

### PrÃ©requis

- Python 3.8 ou supÃ©rieur
- Jupyter Notebook ou JupyterLab

### Installation

1. **Cloner le repository**
```bash
git clone https://github.com/VOTRE_USERNAME/ames-housing-prediction.git
cd ames-housing-prediction
```

2. **CrÃ©er un environnement virtuel** (recommandÃ©)
```bash
python -m venv venv
source venv/bin/activate  # Sur Windows: venv\Scripts\activate
```

3. **Installer les dÃ©pendances**
```bash
pip install -r requirements.txt
```

4. **TÃ©lÃ©charger le dataset**

TÃ©lÃ©chargez le fichier `AmesHousing.csv` depuis [Kaggle](https://www.kaggle.com/datasets/prevek18/ames-housing-dataset) ou utilisez le lien direct du cours et placez-le dans le dossier racine.

5. **Lancer Jupyter Notebook**
```bash
jupyter notebook notebook_final_enrichi.ipynb
```

## ğŸ“Š MÃ©thodologie

### 1. Nettoyage des DonnÃ©es

- **Traitement des valeurs manquantes** : Imputation par mÃ©diane (numÃ©riques) et mode (catÃ©gorielles)
- **Suppression de colonnes** : >50% de valeurs manquantes
- **Gestion des outliers** : Conservation avec transformation log

### 2. Feature Engineering

- **Transformation logarithmique** : Normalisation de la variable cible
  - RÃ©duction de skewness de 1.88 â†’ 0.12
  - AmÃ©lioration de RÂ² : +5-10 points
- **Encodage catÃ©goriel** : Label Encoding pour ~30 variables
- **Standardisation** : Z-score (Î¼=0, Ïƒ=1) pour toutes les features

### 3. ModÃ©lisation

- **Algorithme** : RÃ©gression LinÃ©aire Multiple (OLS)
- **Division** : 80% train / 20% test
- **Validation** : Ã‰vitement rigoureux du data leakage

## ğŸ”‘ Variables les Plus Importantes

| Rang | Variable | Coefficient | Impact |
|------|----------|-------------|--------|
| 1 | BsmtFin SF 1 | +0.419 | Surface sous-sol fini |
| 2 | Bsmt Unf SF | +0.393 | Surface sous-sol non fini |
| 3 | Overall Qual | +0.109 | QualitÃ© gÃ©nÃ©rale |
| 4 | Gr Liv Area | +0.065 | Surface habitable |
| 5 | Garage Cars | +0.041 | CapacitÃ© garage |

## ğŸ“ˆ Visualisations ClÃ©s

Le notebook contient plus de 15 visualisations professionnelles :
- Distributions avant/aprÃ¨s transformation
- Matrices de corrÃ©lation
- Scatter plots des variables principales
- Analyse des rÃ©sidus
- Comparaisons train/test

## ğŸ’¡ Insights et Recommandations

### Points Forts du ModÃ¨le

âœ… **Performance excellente** : RÂ² = 82.60%  
âœ… **SimplicitÃ©** : ModÃ¨le linÃ©aire interprÃ©table  
âœ… **Robustesse** : Pas de biais systÃ©matique  
âœ… **PraticitÃ©** : Rapide Ã  entraÃ®ner et dÃ©ployer

### Axes d'AmÃ©lioration

ğŸš€ **Quick Wins** (+2-5% RÂ²) :
- Feature engineering avancÃ© (interactions, ratios)
- Traitement spÃ©cifique des outliers
- RÃ©gularisation (Ridge/Lasso)

ğŸš€ **AmÃ©liorations AvancÃ©es** (+5-10% RÂ²) :
- Random Forest / XGBoost
- Ensemble methods
- Cross-validation rigoureuse

## ğŸ“ CompÃ©tences DÃ©montrÃ©es

- âœ… **Data Cleaning** : Gestion des valeurs manquantes, outliers
- âœ… **EDA** : Analyses univariÃ©e, bivariÃ©e, multivariÃ©e
- âœ… **Feature Engineering** : Transformations, encodage, standardisation
- âœ… **Modeling** : Pipeline ML complet, prÃ©vention du data leakage
- âœ… **Evaluation** : MÃ©triques multiples, validation rigoureuse
- âœ… **Communication** : Documentation exhaustive, visualisations professionnelles

## ğŸ“± Applications Pratiques

1. **Estimation pour vendeurs** : Aide Ã  la fixation du prix
2. **Ã‰valuation pour acheteurs** : DÃ©tection des bonnes affaires
3. **Analyse d'investissement** : Calcul de ROI aprÃ¨s rÃ©novation
4. **Ã‰tudes de marchÃ©** : Identification des drivers de valeur

## ğŸ‘¤ Auteur

**SYLLA Oumarou**  
Master 2 - Data Science et Machine Learning  
INPHB (Institut National Polytechnique HouphouÃ«t-Boigny)  
CÃ´te d'Ivoire